# [Treinamento de LoRa Pony Realism & Predefini√ß√£o](https://civitai.com/articles/5545/pony-realism-lora-training-and-preset)


![](https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/84922823-a27a-41c9-b5c6-1e22070ad9b5/width=225/title.jpeg)


criado: 18-06-2024
tags: `training guide` `pony diffusion xl` `pony realism` `lora training`
autor: [ZyloO](https://civitai.com/user/ZyloO)

---
## üëã <u>Introdu√ß√£o</u>

Este guia fornece uma vis√£o geral do meu processo de treinamento para LoRas usando meu modelo, [Pony Realism](https://civitai.com/models/372465/pony-realism) para [Kohya_SS](https://github.com/bmaltais/kohya_ss).

Treinar um modelo LoRa envolve v√°rias etapas, desde a prepara√ß√£o do seu conjunto de dados at√© o ajuste fino do modelo para um desempenho ideal. Embora este guia ofere√ßa uma vis√£o geral do meu processo, n√£o entrar√° em detalhes sobre todas as configura√ß√µes, pois estou compartilhando meu preset. Alguns valores precisar√£o ser ajustados com base no seu hardware e dados, como o n√∫mero de **_epochs_** e **_batch size_**.

## üì¶ Preparativos

Primeiro, voc√™ precisar√° de alguns itens indispens√°veis:

1.  **Uma cole√ß√£o de imagens para seu personagem/estilo**: A qualidade √© mais importante que a quantidade. Eu geralmente seleciono de 14 a 50 imagens de alta qualidade.
    
2.  **Legendas**: Voc√™ pode gerar estas usando Kohya_SS _<u>Utilities -> Captioning</u>_. Eu uso principalmente **_WD14 Captioning_**, mas em algumas situa√ß√µes, **_BLIP_** pode ser melhor. Eu adiciono um prefixo √∫nico e executo as configura√ß√µes padr√£o.
    

## üìù C√°lculo dos Passos

O c√°lculo que fa√ßo para os epochs/passo √©:

```
n√∫mero de imagens * passos = ~900
```

Ent√£o, por exemplo, no seguinte conjunto de dados:  
![](https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c5097e5b-2fe5-455b-932e-e9fb2fa1d222/width=525/c5097e5b-2fe5-455b-932e-e9fb2fa1d222.jpeg)
23 imagens * 40 = 920.  
Esse valor **_40_** vai para a pasta como **_numbersubject_**:

![](https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e0a37a47-8792-474f-b080-81f04fdfb3a8/width=525/e0a37a47-8792-474f-b080-81f04fdfb3a8.jpeg)
Por fim, para calcular os epochs eu fa√ßo:  

```
passos * epoch / batch size = ~2500
```

Isso me d√° um epochs de 6:

```
920 * 6 / 2 = 2760
```

## üìú Predefini√ß√µes de Treinamento

As predefini√ß√µes enviadas aqui √© o que uso para tudo, personagem/estilo/conceito, devem estarem prontas para uso, voc√™ pode precisar mudar o batch size e os epochs com base no seu hardware, para refer√™ncia, o meu √© o seguinte:  

-   RTX 4090
    
-   i7 13700k
    
-   64 Gb Ram 6400 MHz
    

## üñº Resultados![](https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5b7ab1e9-984c-47f7-ab12-2783115d976f/width=525/5b7ab1e9-984c-47f7-ab12-2783115d976f.jpeg)![](https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9715a730-5309-4463-96e7-b8f1fa91a8ae/width=525/9715a730-5309-4463-96e7-b8f1fa91a8ae.jpeg)

## Anexos

- [PonyRealismTrainingPreset.json](https://civitai.com/api/download/attachments/59878)
- [AnaArmas.zip](https://civitai.com/api/download/attachments/65149)
- [linda.zip](https://civitai.com/api/download/attachments/65150)

# Coment√°rios
<p>
</p>


> [**fragility_abreast959691**](https://civitai.com/user/fragility_abreast959691)
Alguma sugest√£o de resolu√ß√£o ou propor√ß√£o das imagens de treinamento?

>> [**ZyloO - OP**](https://civitai.com/user/ZyloO)
N√£o realmente, apenas verifique se √© uma imagem de alta qualidade e pronto, h√° o bucketing habilitado em 1024x1024.

---

> [**jeremygin**](https://civitai.com/user/jeremygin)
Oi ZyloO, obrigado por compartilhar sua predefini√ß√£o. Quando voc√™ legenda LoRAs para este modelo, voc√™ usa "female" ou "male" em vez de 1boy/1girl ou man/woman como na base Pony (baseado na sua recomenda√ß√£o nas informa√ß√µes do modelo)?

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
Na maioria das vezes, usando WD14 Captioning, eu uso 1girl/1boy. Quando uso BLIP, mudo para man/woman.

---

> [**ammor**](https://civitai.com/user/ammor)
> √ìtimo artigo, pois voc√™ fornece n√∫meros!
> 
> Diga-me, usando seu exemplo acima, se eu diminuir as repeti√ß√µes e aumentar as √©pocas, na mesma propor√ß√£o, tipo 10 reps & 24 epochs, que tipo de influ√™ncia eu teria no resultado final? O resultado seria muito diferente?
> 
> Obrigado!

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
N√£o acho, no final o que importa s√£o os passos que voc√™ treina, voc√™ pode fazer mais √©pocas e menos repeti√ß√µes ou vice-versa. Uma coisa boa de fazer mais √©pocas do que repeti√ß√µes √© que voc√™ pode salvar mais vers√µes do lora de cada √©poca.

---

> [**ic4rustheb1rd302**](https://civitai.com/user/ic4rustheb1rd302)
Quando voc√™ extrai lora/lycoris, qual √© o rank/alpha configurado?

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
Se voc√™ quer dizer "Network Rank (Dimension)", ent√£o 32, alpha 0.

>>> [**ic4rustheb1rd302**](https://civitai.com/user/ic4rustheb1rd302)
Obrigado!

---

> [**countlippe**](https://civitai.com/user/countlippe)
Obrigado por compartilhar a predefini√ß√£o.

---

> [**[deleted]**](https://civitai.com/user/[deleted])
Qual √© a probabilidade de conseguir fazer um pequeno SDXL LoRa com uma GTX 1060 6GB antiga, mesmo que demore um dia inteiro?

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
As diretrizes do Kohya_ss dizem para usar uma GPU que tenha pelo menos 12GB de mem√≥ria. Voc√™ pode tentar, mas n√£o sei quanto tempo poderia levar. √â melhor usar Runpod ou Collab.

---

> [**SadGolem**](https://civitai.com/user/SadGolem)
Obrigado pelo tutorial! Voc√™ precisa adicionar tags espec√≠ficas como "score_9" nas imagens para o treinamento do pony lora?

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
N√£o, voc√™ s√≥ usa essas ao gerar imagens.

---

> [**hablaba**](https://civitai.com/user/hablaba)
Voc√™ usa um nome ou token √∫nico para seu treinamento de personagem Lora, tipo ‚Äúohwx‚Äù ou apenas aplica a 1girl/woman? √â isso que voc√™ quer dizer com ‚Äúprefixo √∫nico‚Äù?

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
Sim, eu adiciono um token √∫nico.

---

> [**otherworlderotic315**](https://civitai.com/user/otherworlderotic315)
Voc√™ j√° lidou com imagens de baixa resolu√ß√£o / upscaling? Estou portando 1.5 LORAs e s√≥ tenho imagens de baixa resolu√ß√£o. Planejei aumentar a resolu√ß√£o delas, mas se eu pudesse marc√°-las de alguma forma para indicar que s√£o de baixa qualidade e ainda assim ensinar a semelhan√ßa, isso pareceria funcionar intuitivamente.

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
Voc√™ pode tentar usar um upscaler, pessoalmente n√£o tive muita sorte em obter bons resultados dessa forma, pois as imagens tendem a perder muitos detalhes.

---

> [**chrisss1**](https://civitai.com/user/chrisss1)
Oi, isso parece muito √∫til, obrigado. Existe alguma maneira de tornar o personagem menos uncanny valley? N√£o tentei o Pony Realism, mas usei o EverClear v2+VAE e os Loras de personagens reais que fiz tiveram resultados muito ruins. Criei um com 200 imagens de alta qualidade usando o treinamento lora do civitai, mas como disse, os resultados n√£o se parecem com a pessoa. Sempre miro em mais de 1k passos. Estou fazendo algo errado?

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
N√£o tenho certeza, mas voc√™ pode precisar testar as sa√≠das neste modelo. Tentei usar o site LoRa trainer duas vezes e ambas as vezes obtive resultados ruins. Portanto, prefiro fazer o treinamento local usando kohya_ss. Nos passos, miro em 2.500.

>>> [**chrisss1**](https://civitai.com/user/chrisss1)
Obrigado, vou tentar localmente e tamb√©m o Pony Realism.

---

> [**karlobeat**](https://civitai.com/user/karlobeat)
Oi, primeiro de tudo, obrigado por todo esse trabalho!
Estou tentando treinar kohya ss com pony realism, usei seu arquivo json e 41 fotos originais do iPhone. Infelizmente, ao transferir o checkpoint lora para o arquivo lora dentro do stable diffusion, meus resultados foram bem ruins. Coloquei pony realism na se√ß√£o do modelo do sd, VAE autom√°tico. Ent√£o todos os dpm++, euler a e DPM2a, mas nada parece funcionar. Os rostos do meu sujeito original est√£o errados. Tentei CFG 2, 5, 8 e ainda nada. O que voc√™ acha que estou fazendo de errado? (minhas fotos s√£o da mesma pessoa, diferentes express√µes, √†s vezes cortadas no rosto, √†s vezes no corpo inteiro em p√© para que se concentre na pessoa e n√£o nas pessoas ao redor). Obrigado se puder me ajudar!

>>  [**ZyloO - OP**](https://civitai.com/user/ZyloO)
Voc√™ legendou as imagens?
O √∫nico problema que consigo pensar √© a qualidade das imagens. Notei que no treinamento para SDXL e Pony (PonyRealism) com conjuntos de dados de pessoas reais, a qualidade das imagens faz uma diferen√ßa significativa. Tente fazer suas imagens o mais alta qualidade poss√≠vel, mesmo que isso signifique reduzir seu conjunto de dados pela metade. Al√©m disso, em vez de reduzir o CFG, brinque com a for√ßa do lora.

>>> [**cosmoslayer26**](https://civitai.com/user/cosmoslayer26)
N√£o sou o OP, mas tamb√©m tenho os mesmos problemas. Legendei as imagens e defini a quantidade apropriada de epochs/reps para obter 2.6k passos e a sa√≠da n√£o se parece em nada com o sujeito no conjunto de dados.

>>>> [**arslan2012**](https://civitai.com/user/arslan2012)
Tamb√©m tive os mesmos problemas, estava fazendo 150 imagens com 7 repeti√ß√µes, e acabei aumentando a taxa de aprendizado para 0.001 por 5 √©pocas antes que a imagem come√ßasse a se parecer com o sujeito, e depois voltei a taxa de aprendizado para o padr√£o.

---

> [**RedDeltas**](https://civitai.com/user/RedDeltas)
Obrigado pelo artigo, √© √≥timo quando as pessoas compartilham seu processo. Voc√™ j√° tentou usar isso para treinamento Dreambooth?

>> [**ZyloO - OP**](https://civitai.com/user/ZyloO)
N√£o, ainda n√£o tentei Dreambooth.

>>> [**RedDeltas**](https://civitai.com/user/RedDeltas)
Legal, eu tenho um conjunto de dados que j√° estou usando para treinamento LoRA, ent√£o posso tentar isso em ambos e ver como fica.

---

> [**RedDeltas**](https://civitai.com/user/RedDeltas)
Tentei treinar no Dreambooth em vez disso e os resultados foram incr√≠veis, definitivamente vale a pena voc√™ tentar.

>> [**fr0g**](https://civitai.com/user/fr0g)
Voc√™ se importaria de compartilhar quais par√¢metros voc√™ usou para dreambooth?

>>> [**RedDeltas**](https://civitai.com/user/RedDeltas)
Usei os par√¢metros padr√£o do SECourses, que usam AdaFactor e suas imagens de reg. Vale a pena se inscrever no Patreon dele para obter todas as suas coisas - ele faz muitos testes que lhe custam dinheiro, ent√£o √© bom retribuir - custa apenas $5.

---

> [**ainow**](https://civitai.com/user/ainow)
Para pony realism voc√™ sugere clip skip 2... mas a predefini

√ß√£o de treinamento LoRa usa clip skip 1... o clip skip n√£o deveria estar definido para 2?

>> [**Clocksmith**](https://civitai.com/user/Clocksmith)
Eu verifiquei com uma configura√ß√£o Everclear que me deu os melhores resultados e de fato tinha clip skip definido para 2, ao contr√°rio do arquivo nesta p√°gina. Estou testando um lora com dados de entrada id√™nticos ao bom resultado do Everclear e mudando clip skip no arquivo desta p√°gina para 2. Vou relatar os resultados.

>> [**Clocksmith**](https://civitai.com/user/Clocksmith)
Sim. Confirmado. Treinei as mesmas imagens, legendas, passos e √©pocas com o arquivo como est√° e com clip skip 2. Literalmente, a √∫nica coisa que mudei. A semelhan√ßa com o arquivo atual n√£o se parece nada com as imagens de treinamento e a semelhan√ßa com clip skip 2 est√° perfeita. Voc√™ precisa mudar seu arquivo para ter clip skip 2, ZyloO.

>>> [**ZyloO - OP**](https://civitai.com/user/ZyloO)
At√© agora tive bons resultados usando clip skip 1, mas vou tentar usar 2, parece fazer mais sentido, obrigado.

---

> [**Clocksmith**](https://civitai.com/user/Clocksmith)
Voc√™ pode postar o exemplo de lora que tem as pastas para que possamos ter uma ideia dos resultados esperados para um lora baseado em foto?

>> [**ZyloO - OP**](https://civitai.com/user/ZyloO)
Claro, enviei os dois conjuntos de dados.

>>> [**Clocksmith**](https://civitai.com/user/Clocksmith)
√ìtimo! Obrigado!

>>> [**Clocksmith**](https://civitai.com/user/Clocksmith)
Voc√™ tamb√©m pode compartilhar o prompt que usou para criar sua imagem de amostra, especificamente com o lora `xanrms`, incluindo o peso do lora? Estou tentando testar o efeito do clip skip, mas n√£o tenho certeza se estou fazendo o prompt da mesma forma que voc√™.

>>>> [**ZyloO - OP**](https://civitai.com/user/ZyloO)
Positivo:
score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, BREAK, RAW, xanrms, mid-shot, portrait, cozy bedroom, wearing dress, photo, 8k, very sharp, very detailed, realistic, real, hyper realistic, detailed eyes, natural lighting, god rays, cinematic view, <lora:ana_armas_pony_realism_v1:.85>
>>>>
>>>> Prompt negativo:
>>>>
>>>> score_1, score_2, score_3, text, 3d, deformed, deformed face, low quality, bad quality, worst quality, (drawn, furry, illustration, cartoon, anime, comic:1.5), 3d, cgi, extra fingers, (source_anime, source_cartoon, source_furyy, source_western, source_comic, source_pony), deformed teeth, plain background
>>>> 
>>>> Passos: 30, Amostrador: DPM++ 2S a Karras, Escala CFG: 6, Seed: 3281991511, Tamanho: 768x1280
>>>> 
>>>> Clip skip: 2, Modelo ADetailer: face_yolov8s.pt

---

> [**embis0126878**](https://civitai.com/user/embis0126878)
Sim, segui todos os passos exatamente como voc√™ disse e meus resultados foram terr√≠veis. A semelhan√ßa que voc√™ mostra nos seus resultados √© incr√≠vel, mas eu n√£o consigo replicar.

>> [**mogmog**](https://civitai.com/user/mogmog)
Mesmo aqui. E eu tenho imagens de fonte incrivelmente detalhadas e de alta resolu√ß√£o, ent√£o sei que n√£o √© isso. Me pergunto se √© porque minha fonte n√£o √© conhecida pelo modelo base, √© uma pessoa personalizada.

---
